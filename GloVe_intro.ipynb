{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEMvqJ2xGjVC"
      },
      "outputs": [],
      "source": [
        "# import the libraries\n",
        "import torch\n",
        "import torchtext.vocab as vocab\n",
        "# %% Code Change because of GloVe download issue\n",
        "# solution provided by Mitchell Miller\n",
        "#glove = vocab.GloVe(name='6B', dim =100)\n",
        "from torchtext.vocab import Vectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class newGloVe(Vectors):\n",
        "    url = {\n",
        "        \"42B\": \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.42B.300d.zip\",\n",
        "        \"840B\": \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.840B.300d.zip\",\n",
        "        \"twitter.27B\": \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.twitter.27B.zip\",\n",
        "        \"6B\": \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, name=\"840B\", dim=300, **kwargs) -> None:\n",
        "        url = self.url[name]\n",
        "        print(f\"Downloading from {url}\")\n",
        "        # Use the 'dim' parameter to construct the filename\n",
        "        name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
        "        # Remove 'dim' from kwargs as it is not a parameter of Vectors.__init__\n",
        "        super(newGloVe, self).__init__(name, url=url, **kwargs)\n",
        "\n",
        "glove = newGloVe(name='6B', dim=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muzmQVWFdIC7",
        "outputId": "473e7bee-303c-45d5-d1e9-0b17f6f87775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of words and embeddings\n",
        "glove.vectors.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU30gaq3i1lB",
        "outputId": "3624bb39-4ce4-4139-d76c-03b26c0ad9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400000, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get an embedding vector\n",
        "def get_embedding_vector(word):\n",
        "    word_index = glove.stoi[word]\n",
        "    emb = glove.vectors[word_index]\n",
        "    return emb"
      ],
      "metadata": {
        "id": "fj8nev5WjB4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "get_embedding_vector('chess').shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06UWtOrEjQD1",
        "outputId": "efb802bc-a741-4056-f26e-0c765af31955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find closest words from input word\n",
        "def get_closest_words_from_word(word, max_n=5):\n",
        "    word_emb = get_embedding_vector(word)\n",
        "    distances = [(w, torch.dist(word_emb, get_embedding_vector(w)).cpu().item()) for w in glove.itos]\n",
        "    dist_sort_filt = sorted(distances, key=lambda x: x[1])[:max_n]\n",
        "    return dist_sort_filt\n"
      ],
      "metadata": {
        "id": "-otcGZrwjTW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_closest_words_from_word('chess')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqP9XFBvjZJN",
        "outputId": "062477f5-4d4c-4c88-daf8-d5557f269062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chess', 0.0),\n",
              " ('backgammon', 4.379469394683838),\n",
              " ('grandmasters', 4.56368350982666),\n",
              " ('grandmaster', 4.613785743713379),\n",
              " ('scrabble', 4.677640438079834)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find closest words from embedding\n",
        "def get_closest_words_from_embedding(word_emb, max_n=5):\n",
        "    distances = [(w, torch.dist(word_emb, get_embedding_vector(w)).cpu().item()) for w in glove.itos]\n",
        "    dist_sort_filt = sorted(distances, key=lambda x: x[1])[:max_n]\n",
        "    return dist_sort_filt"
      ],
      "metadata": {
        "id": "SN6jt9CGjcUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find word analogies\n",
        "# e.g. King is to Queen like Man is to Woman\n",
        "def get_word_analogy(word1, word2, word3, max_n=5):\n",
        "    # logic w1= king, ...\n",
        "    # w1 - w2 + w3 --> w4\n",
        "    word1_emb = get_embedding_vector(word1)\n",
        "    word2_emb = get_embedding_vector(word2)\n",
        "    word3_emb = get_embedding_vector(word3)\n",
        "    word4_emb = word1_emb - word2_emb + word3_emb\n",
        "    analogy = get_closest_words_from_embedding(word4_emb)\n",
        "    return analogy\n",
        "\n",
        "get_word_analogy(word1='sister', word2='brother', word3='nephew')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMd09PsDjgFN",
        "outputId": "25db552d-f48c-40bb-aaa8-32d949d81f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sister', 2.5398471355438232),\n",
              " ('niece', 2.700707197189331),\n",
              " ('granddaughter', 3.272900342941284),\n",
              " ('sister-in-law', 3.652935743331909),\n",
              " ('cousin', 3.657327651977539)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdNiu2QzjnaL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}